# ğŸ¤– LLM åˆ° Anthropic ä»£ç†

<div align="center">

![Go Version](https://img.shields.io/badge/Go-1.22+-00ADD8?style=flat&logo=go)
![License](https://img.shields.io/badge/License-MIT-green?style=flat)
![Build](https://img.shields.io/badge/Build-Passing-brightgreen?style=flat)
![Release](https://img.shields.io/github/v/release/nerdneilsfield/llm-to-anthropic?style=flat&logo=github)
![Docker Hub](https://img.shields.io/docker/v/nerdneilsfield/llm-to-anthropic?style=flat&logo=docker)
![GHCR](https://img.shields.io/badge/ghcr.io-latest-blue?style=flat&logo=github)
![Issues](https://img.shields.io/github/issues/nerdneilsfield/llm-to-anthropic?style=flat)
![Forks](https://img.shields.io/github/forks/nerdneilsfield/llm-to-anthropic?style=flat)
![Stars](https://img.shields.io/github/stars/nerdneilsfield/llm-to-anthropic?style=flat)

**ä¸€ä¸ªçµæ´»çš„ LLM API ä»£ç†ï¼Œå°†å„ç§ LLM æä¾›å•†è½¬æ¢ä¸ºç»Ÿä¸€çš„ Anthropic å…¼å®¹æ ¼å¼**

[å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢ [é…ç½®](#-é…ç½®) â€¢ [API æ–‡æ¡£](#-api-å‚è€ƒ) â€¢ [Docker](#-docker-å’Œéƒ¨ç½²) â€¢ [ç¤ºä¾‹](#-ç¤ºä¾‹)

</div>

---

## âœ¨ ç‰¹æ€§

- ğŸ¯ **å¤šæä¾›å•†æ”¯æŒ** - é…ç½®ä»»æ„æ•°é‡çš„ LLM æä¾›å•†ï¼ˆOpenAIã€Anthropicã€Google Geminiã€Ollama ç­‰ï¼‰
- ğŸ”‘ **çµæ´»çš„ API Key** - æ”¯æŒç›´æ¥ keyã€ç¯å¢ƒå˜é‡æˆ–ç»•è¿‡æ¨¡å¼
- ğŸ”„ **æ¨¡å‹æ˜ å°„** - å°†ç®€å•åç§°å¦‚ `haiku` æ˜ å°„åˆ°ä»»ä½•æä¾›å•†/æ¨¡å‹ç»„åˆ
- ğŸš€ **å®¢æˆ·ç«¯ Key** - å°†å®¢æˆ·ç«¯ API Key è½¬å‘åˆ°æä¾›å•†ï¼ˆç»•è¿‡æ¨¡å¼ï¼‰
- âš¡ **é«˜æ€§èƒ½** - ä½¿ç”¨ Fiber v2 å’Œ fasthttp æ„å»ºï¼Œé€Ÿåº¦é£å¿«
- ğŸ›¡ï¸ **é…ç½®éªŒè¯** - å¯åŠ¨æ—¶éªŒè¯æ‰€æœ‰è®¾ç½®ï¼Œæä¾›æ¸…æ™°çš„é”™è¯¯æ¶ˆæ¯
- ğŸ“ **Anthropic å…¼å®¹** - Anthropic API çš„ç›´æ¥æ›¿ä»£å“

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

é€‰æ‹©ä»¥ä¸‹ä»»ä¸€å®‰è£…æ–¹å¼ï¼š

#### æ–¹å¼ 1ï¼šä¸‹è½½é¢„æ„å»ºäºŒè¿›åˆ¶ï¼ˆæ¨èï¼‰

```bash
# ä¸‹è½½é€‚ç”¨äºæ‚¨å¹³å°çš„æœ€æ–°äºŒè¿›åˆ¶æ–‡ä»¶
# Linux AMD64
wget https://github.com/nerdneilsfield/llm-to-anthropic/releases/latest/download/llm-to-anthropic-linux-amd64 -O llm-to-anthropic

# macOS AMD64
wget https://github.com/nerdneilsfield/llm-to-anthropic/releases/latest/download/llm-to-anthropic-darwin-amd64 -O llm-to-anthropic

# Windows AMD64
wget https://github.com/nerdneilsfield/llm-to-anthropic/releases/latest/download/llm-to-anthropic-windows-amd64.exe -O llm-to-anthropic.exe

# æ·»åŠ æ‰§è¡Œæƒé™ï¼ˆLinux/macOSï¼‰
chmod +x llm-to-anthropic

# è¿è¡Œ
./llm-to-anthropic serve
```

#### æ–¹å¼ 2ï¼šä½¿ç”¨ Docker

```bash
# æ‹‰å–å¹¶è¿è¡Œé•œåƒ
docker run -d \
  -p 8082:8082 \
  -v $(pwd)/config.toml:/app/config.toml \
  nerdneilsfield/llm-to-anthropic:latest

# æˆ–ä½¿ç”¨ GitHub Container Registry
docker run -d \
  -p 8082:8082 \
  -v $(pwd)/config.toml:/app/config.toml \
  ghcr.io/nerdneilsfield/llm-to-anthropic:latest
```

#### æ–¹å¼ 3ï¼šä»æºç æ„å»º

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/nerdneilsfield/llm-to-anthropic.git
cd llm-to-anthropic

# ä»æºç æ„å»º
go build -o llm-to-anthropic .

# è¿è¡Œ
./llm-to-anthropic serve
```

### æœ€å°åŒ–é…ç½®

åˆ›å»º `config.toml`:

```toml
[server]
host = "0.0.0.0"
port = 8082

[[providers]]
name = "openai"
type = "openai"
api_base_url = "https://api.openai.com/v1"
api_key = "env:OPENAI_API_KEY"
models = ["gpt-4o", "gpt-4.1-mini"]
```

### å‘èµ·ç¬¬ä¸€ä¸ªè¯·æ±‚

```bash
curl -X POST http://localhost:8082/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-api-key: ä½ çš„-openai-api-key" \
  -d '{
    "model": "openai/gpt-4o",
    "max_tokens": 1024,
    "messages": [
      {"role": "user", "content": "ä½ å¥½ï¼"}
    ]
  }'
```

---

## ğŸ³ Docker å’Œéƒ¨ç½²

Docker ä½¿ç”¨å’Œéƒ¨ç½²æŒ‡å—ï¼š

- ğŸ“¦ [Docker ä½¿ç”¨æŒ‡å—](DOCKER.md) - ä½¿ç”¨ Docker æˆ– Docker Compose è¿è¡Œ
- ğŸš€ [éƒ¨ç½²æŒ‡å—](DEPLOYMENT.md) - å‘å¸ƒæµç¨‹ã€CI/CDã€ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- ğŸ” [å®‰å…¨æœ€ä½³å®è·µ](#-å®‰å…¨æœ€ä½³å®è·µ)

---

## ğŸ“– é…ç½®

### åŸºæœ¬ç»“æ„

```toml
[server]
host = "0.0.0.0"
port = 8082
read_timeout = 120
write_timeout = 120

# å®šä¹‰å¤šä¸ªæä¾›å•†
[[providers]]
name = "openai"
type = "openai"
api_base_url = "https://api.openai.com/v1"
api_key = "env:OPENAI_API_KEY"
models = ["gpt-4o", "gpt-4.1-mini"]

[[providers]]
name = "ollama"
type = "openai"
api_base_url = "http://localhost:11434/v1"
api_key = "bypass"
models = ["llama3.2:3b", "llama3.2:7b"]

# æ¨¡å‹æ˜ å°„
[mappings]
"haiku" = "ollama/llama3.2:3b"
"sonnet" = "ollama/llama3.2:7b"
```

<details>
<summary><strong>ğŸ”§ é«˜çº§é…ç½®é€‰é¡¹</strong></summary>

### API Key é…ç½®

æ”¯æŒä¸‰ç§æ¨¡å¼ï¼š

#### 1. ç›´æ¥ Key
```toml
api_key = "sk-xxxxxxxxxxxxxxxx"
```
ç›´æ¥åœ¨é…ç½®æ–‡ä»¶ä¸­å†™å…¥ API keyã€‚

#### 2. ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰
```toml
api_key = "env:OPENAI_API_KEY"
```
ä»ç¯å¢ƒå˜é‡è¯»å–ã€‚ä»£ç†ä¼šåœ¨å¯åŠ¨æ—¶éªŒè¯è¯¥å˜é‡å­˜åœ¨ä¸”ä¸ä¸ºç©ºã€‚

#### 3. ç»•è¿‡/è½¬å‘æ¨¡å¼
```toml
api_key = "bypass"  # æˆ– "forward"
```
å°†å®¢æˆ·ç«¯çš„ `X-API-Key` è¯·æ±‚å¤´è½¬å‘ç»™æä¾›å•†ã€‚é€‚ç”¨äºå¸Œæœ›å®¢æˆ·ç«¯ç®¡ç†è‡ªå·±çš„ key çš„åœºæ™¯ã€‚

### æä¾›å•†ç±»å‹

| ç±»å‹ | æè¿° | ç¤ºä¾‹ |
|------|-------------|----------|
| `openai` | OpenAI å…¼å®¹ API | OpenAIã€Azureã€Ollamaã€DeepSeek |
| `anthropic` | Anthropic API | Claude æ¨¡å‹ |
| `gemini` | Google Gemini API | Gemini æ¨¡å‹ |

### æ¨¡å‹é€‰æ‹©

ä½¿ç”¨ `provider/model` æ ¼å¼ï¼š

```bash
# ç›´æ¥æŒ‡å®š provider/model
curl -d '{"model": "openai/gpt-4o", ...}'

# æˆ–ä½¿ç”¨æ˜ å°„
curl -d '{"model": "haiku", ...}'  # æ˜ å°„åˆ° "ollama/llama3.2:3b"
```

### Vertex AI é…ç½®

å¯¹äº Google Vertex AIï¼š

```toml
[[providers]]
name = "vertex"
type = "gemini"
api_base_url = "https://us-central1-aiplatform.googleapis.com/v1"
api_key = "bypass"
use_vertex_auth = true
vertex_project = "your-project-id"
vertex_location = "us-central1"
models = ["gemini-2.5-pro"]
```

### é…ç½®éªŒè¯

ä»£ç†åœ¨å¯åŠ¨æ—¶éªŒè¯æ‰€æœ‰è®¾ç½®ï¼š

```bash
# ç¤ºä¾‹éªŒè¯é”™è¯¯
Failed to load configuration: invalid configuration: 
  provider openai: environment variable 'OPENAI_API_KEY' is not set or is empty

Failed to load configuration: invalid configuration: 
  provider openai: models list is required and must not be empty

Failed to load configuration: invalid configuration: 
  mapping: alias 'test' references non-existent provider 'nonexistent'
```

æŸ¥çœ‹ [CONFIGURATION_VALIDATION.md](CONFIGURATION_VALIDATION.md) äº†è§£å®Œæ•´çš„éªŒè¯è§„åˆ™ã€‚

</details>

---

## ğŸ“š API å‚è€ƒ

### å¥åº·æ£€æŸ¥ç«¯ç‚¹

#### GET /health
åŸºæœ¬å¥åº·æ£€æŸ¥ã€‚

```bash
curl http://localhost:8082/health
```

**å“åº”ï¼š**
```json
{
  "status": "ok"
}
```

#### GET /health/ready
å°±ç»ªæ£€æŸ¥ï¼ŒåŒ…å«æä¾›å•†çŠ¶æ€ã€‚

```bash
curl http://localhost:8082/health/ready
```

**å“åº”ï¼š**
```json
{
  "status": "ready",
  "providers": {
    "openai": "configured",
    "ollama": "configured"
  },
  "total_providers": 2,
  "total_mappings": 2
}
```

### æ¶ˆæ¯ç«¯ç‚¹

#### POST /v1/messages
ä½¿ç”¨ Anthropic API æ ¼å¼å‘é€æ¶ˆæ¯ã€‚

```bash
curl -X POST http://localhost:8082/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-api-key: ä½ çš„-api-key" \
  -d '{
    "model": "openai/gpt-4o",
    "max_tokens": 1024,
    "messages": [
      {"role": "user", "content": "ä½ å¥½ï¼"}
    ]
  }'
```

**è¯·æ±‚ä½“ï¼š**
| å­—æ®µ | ç±»å‹ | å¿…éœ€ | æè¿° |
|-------|------|------|-------------|
| `model` | string | æ˜¯ | æ¨¡å‹æ ‡è¯†ç¬¦ï¼ˆä¾‹å¦‚ï¼š`openai/gpt-4o`ï¼‰|
| `max_tokens` | integer | æ˜¯ | æœ€å¤§ç”Ÿæˆçš„ token æ•° |
| `messages` | array | æ˜¯ | æ¶ˆæ¯å¯¹è±¡æ•°ç»„ |
| `stream` | boolean | å¦ | å¯ç”¨æµå¼ä¼ è¾“ï¼ˆé»˜è®¤ï¼šfalseï¼‰|

**å“åº”ï¼š**
```json
{
  "id": "msg_123",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "ä½ å¥½ï¼ä»Šå¤©æˆ‘å¯ä»¥å¸®ä½ ä»€ä¹ˆï¼Ÿ"
    }
  ],
  "model": "openai/gpt-4o",
  "stop_reason": "end_turn",
  "usage": {
    "input_tokens": 10,
    "output_tokens": 20
  }
}
```

### æ¨¡å‹ç«¯ç‚¹

#### GET /v1/models
åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹ã€‚

```bash
curl http://localhost:8082/v1/models
```

**å“åº”ï¼š**
```json
{
  "object": "list",
  "data": [
    {
      "id": "openai/gpt-4o",
      "object": "model",
      "created": 1234567890,
      "owned_by": "openai"
    },
    {
      "id": "ollama/llama3.2:3b",
      "object": "model",
      "created": 1234567890,
      "owned_by": "ollama"
    }
  ]
}
```

<details>
<summary><strong>ğŸ”§ é«˜çº§ API ç”¨æ³•</strong></summary>

### æµå¼å“åº”

è®¾ç½® `stream: true` å¯ç”¨æµå¼ä¼ è¾“ï¼š

```bash
curl -X POST http://localhost:8082/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-api-key: ä½ çš„-api-key" \
  -d '{
    "model": "openai/gpt-4o",
    "max_tokens": 1024,
    "stream": true,
    "messages": [
      {"role": "user", "content": "ä½ å¥½ï¼"}
    ]
  }'
```

å“åº”å°†ä»¥æœåŠ¡å™¨å‘é€äº‹ä»¶ï¼ˆSSEï¼‰æ ¼å¼å‘é€ã€‚

### é”™è¯¯å“åº”

æ‰€æœ‰é”™è¯¯éƒ½éµå¾ª Anthropic API é”™è¯¯æ ¼å¼ï¼š

```json
{
  "type": "invalid_request_error",
  "error": {
    "type": "invalid_request_error",
    "message": "model field is required"
  }
}
```

### é€Ÿç‡é™åˆ¶

ä»£ç†ä¸å®ç°é€Ÿç‡é™åˆ¶ã€‚é€Ÿç‡é™åˆ¶ç”±ä¸Šæ¸¸æä¾›å•†å¤„ç†ã€‚

### è®¤è¯

ä»£ç†æ”¯æŒä¸¤ç§è®¤è¯æ¨¡å¼ï¼š

1. **æœåŠ¡ç«¯**ï¼šAPI key åœ¨ `config.toml` ä¸­é…ç½®
2. **å®¢æˆ·ç«¯**ï¼ˆç»•è¿‡ï¼‰ï¼šå®¢æˆ·ç«¯é€šè¿‡ `X-API-Key` è¯·æ±‚å¤´æä¾›è‡ªå·±çš„ API key

åœ¨ç»•è¿‡æ¨¡å¼ä¸‹ï¼Œ`X-API-Key` è¯·æ±‚å¤´ä¼šè¢«è½¬å‘ç»™æä¾›å•†ã€‚

</details>

---

## ğŸ¯ ç¤ºä¾‹

<details>
<summary><strong>ğŸ“ ç¤ºä¾‹ 1ï¼šå¤šä¸ªæä¾›å•†</strong></summary>

```toml
[[providers]]
name = "openai"
type = "openai"
api_base_url = "https://api.openai.com/v1"
api_key = "env:OPENAI_API_KEY"
models = ["gpt-4o", "gpt-4.1-mini"]

[[providers]]
name = "anthropic"
type = "anthropic"
api_base_url = "https://api.anthropic.com"
api_key = "env:ANTHROPIC_API_KEY"
models = ["claude-3-5-sonnet-20241022", "claude-haiku-4-20250514"]

[[providers]]
name = "ollama"
type = "openai"
api_base_url = "http://localhost:11434/v1"
api_key = "bypass"
models = ["llama3.2:3b", "llama3.2:7b"]
```

```bash
# ä½¿ç”¨ OpenAI
curl -d '{"model": "openai/gpt-4o", ...}'

# ä½¿ç”¨ Anthropic
curl -d '{"model": "anthropic/claude-3-5-sonnet-20241022", ...}'

# ä½¿ç”¨ Ollama
curl -d '{"model": "ollama/llama3.2:7b", ...}'
```

</details>

<details>
<summary><strong>ğŸ“ ç¤ºä¾‹ 2ï¼šæ¨¡å‹æ˜ å°„</strong></summary>

```toml
[mappings]
"haiku" = "ollama/llama3.2:1b"
"sonnet" = "ollama/llama3.2:3b"
"opus" = "ollama/llama3.2:7b"
"claude" = "anthropic/claude-3-5-sonnet-20241022"
"gpt" = "openai/gpt-4o"
```

```bash
# ç®€å•åç§°
curl -d '{"model": "haiku", ...}'   # ä½¿ç”¨ ollama/llama3.2:1b
curl -d '{"model": "sonnet", ...}'  # ä½¿ç”¨ ollama/llama3.2:3b
curl -d '{"model": "claude", ...}'  # ä½¿ç”¨ anthropic/claude-3-5-sonnet-20241022
```

</details>

<details>
<summary><strong>ğŸ“ ç¤ºä¾‹ 3ï¼šè‡ªå®šä¹‰ OpenAI å…¼å®¹ API</strong></summary>

```toml
[[providers]]
name = "deepseek"
type = "openai"
api_base_url = "https://api.deepseek.com/v1"
api_key = "bypass"  # è®©å®¢æˆ·ç«¯æä¾›è‡ªå·±çš„ key
models = ["deepseek-chat", "deepseek-coder"]
```

```bash
curl -X POST http://localhost:8082/v1/messages \
  -H "x-api-key: ä½ çš„-deepseek-api-key" \
  -d '{"model": "deepseek/deepseek-chat", ...}'
```

</details>

<details>
<summary><strong>ğŸ“ ç¤ºä¾‹ 4ï¼šä½¿ç”¨ Ollama çš„æœ¬åœ° LLM</strong></summary>

```toml
[[providers]]
name = "local"
type = "openai"
api_base_url = "http://localhost:11434/v1"
api_key = "bypass"
models = ["llama3.2:1b", "llama3.2:3b", "llama3.2:7b"]

[mappings]
"å¿«é€Ÿ" = "local/llama3.2:1b"
"å¹³è¡¡" = "local/llama3.2:3b"
"å¼ºåŠ›" = "local/llama3.2:7b"
```

```bash
# ä½¿ç”¨æœ¬åœ° LLM
curl -d '{"model": "local/llama3.2:7b", ...}'
curl -d '{"model": "å¼ºåŠ›", ...}'  # åŒä¸Š
```

</details>

---

## ğŸ› ï¸ å¼€å‘

### ä»æºç æ„å»º

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/nerdneilsfield/llm-to-anthropic.git
cd llm-to-anthropic

# æ„å»º
go build -o llm-to-anthropic .

# è¿è¡Œæµ‹è¯•
go test ./...

# è¿è¡ŒéªŒè¯æµ‹è¯•
./test_validation.sh
```

### é¡¹ç›®ç»“æ„

```
llm-to-anthropic/
â”œâ”€â”€ cmd/                # CLI å‘½ä»¤
â”‚   â”œâ”€â”€ proxy/         # ä»£ç†å‘½ä»¤
â”‚   â””â”€â”€ root.go       # æ ¹å‘½ä»¤
â”œâ”€â”€ internal/          # å†…éƒ¨åŒ…
â”‚   â”œâ”€â”€ config/       # é…ç½®
â”‚   â”œâ”€â”€ server/       # HTTP æœåŠ¡å™¨
â”‚   â””â”€â”€ ...          # å…¶ä»–å†…éƒ¨åŒ…
â”œâ”€â”€ pkg/              # å…¬å…±åŒ…
â”‚   â”œâ”€â”€ provider/      # æä¾›å•†å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ api/          # API å¤„ç†å™¨
â”‚   â””â”€â”€ logger/       # æ—¥å¿—
â”œâ”€â”€ config.toml       # é…ç½®æ–‡ä»¶
â”œâ”€â”€ README.md         # è‹±æ–‡æ–‡æ¡£
â”œâ”€â”€ README_zh.md     # ä¸­æ–‡æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â””â”€â”€ main.go           # å…¥å£ç‚¹
```

### è´¡çŒ®æŒ‡å—

1. Fork ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ï¼ˆ`git checkout -b feature/amazing-feature`ï¼‰
3. æäº¤ä½ çš„æ›´æ”¹ï¼ˆä½¿ç”¨ conventional commitsï¼š`feat:`ã€`fix:`ã€`docs:` ç­‰ï¼‰
4. æ¨é€åˆ°åˆ†æ”¯ï¼ˆ`git push origin feature/amazing-feature`ï¼‰
5. åˆ›å»º Pull Request

---

## ğŸ“„ è®¸å¯è¯

MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

---

## ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ

1. **æ°¸è¿œä¸è¦æäº¤ API key** åˆ°ä»“åº“
2. **ä½¿ç”¨ç¯å¢ƒå˜é‡** è¿›è¡Œæ•æ„Ÿé…ç½®
3. **è®¾ç½®æ­£ç¡®çš„æ–‡ä»¶æƒé™** å¯¹ config.tomlï¼ˆ`chmod 600`ï¼‰
4. **åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ HTTPS**
5. **ä¿æŒé•œåƒæ›´æ–°** ä»¥è·å–å®‰å…¨è¡¥ä¸
6. **å®šæœŸå®¡æŸ¥ä¾èµ–é¡¹** æŸ¥æ‰¾æ¼æ´
7. **åœ¨æä¾›å•†çº§åˆ«ä½¿ç”¨é€Ÿç‡é™åˆ¶**
8. **ç›‘æ§æ—¥å¿—** æŸ¥æ‰¾å¯ç–‘æ´»åŠ¨
9. **åœ¨åå‘ä»£ç†ä¸­å®ç°è®¤è¯**ï¼ˆå¦‚æœéœ€è¦ï¼‰
10. **å®šæœŸå¤‡ä»½** é…ç½®æ–‡ä»¶

---

## ğŸ¤ æ”¯æŒ

- ğŸ“– [æ–‡æ¡£](CONFIGURATION_VALIDATION.md)
- ğŸ› [é—®é¢˜è·Ÿè¸ª](https://github.com/nerdneilsfield/llm-to-anthropic/issues)
- ğŸ’¬ [è®¨è®º](https://github.com/nerdneilsfield/llm-to-anthropic/discussions)
- ğŸ“¦ [Releases](https://github.com/nerdneilsfield/llm-to-anthropic/releases)
- ğŸ³ [Docker Hub](https://hub.docker.com/r/nerdneilsfield/llm-to-anthropic)
- ğŸ“¦ [GitHub Container Registry](https://github.com/nerdneilsfield/llm-to-anthropic/pkgs/container/llm-to-anthropic)

---

<div align="center">

**ç”±ç¤¾åŒºç”¨ â¤ï¸ åˆ¶ä½œ**

[â¬† è¿”å›é¡¶éƒ¨](#-llm-åˆ°-anthropic-ä»£ç†)

</div>
